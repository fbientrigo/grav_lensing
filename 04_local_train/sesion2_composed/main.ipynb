{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_main.ipynb\n",
    "from grav_lens import get_datasets\n",
    "\n",
    "from utils.model import create_model\n",
    "from utils.loadsave import load_model_with_hyperparameters, load_hyperparameters, save_hyperparameters\n",
    "from utils.optimize import dimensions, default_parameters\n",
    "\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data folder: ..\\..\\data\\1\n",
      "Train X: (32, 128, 128, 3)\n",
      "Train Y: (32, 128, 128, 1)\n",
      "Val X: (32, 128, 128, 3)\n",
      "Val Y: (32, 128, 128, 1)\n",
      "Test X: (32, 128, 128, 3)\n",
      "Test Y: (32, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# mi carpeta data se encuentra en el root\n",
    "home_data = os.path.join(\"..\", \"..\")\n",
    "# Ejemplo de uso\n",
    "# INDEX 0 es una carpeta de datasets mucho mas chica\n",
    "train_dataset, val_dataset, test_dataset = get_datasets(data_index='1', max_files=500, home=home_data)\n",
    "\n",
    "for X, Y in train_dataset.take(1):  # Mostrar un batch de entrenamiento\n",
    "    print(\"Train X:\", X.shape)\n",
    "    print(\"Train Y:\", Y.shape)\n",
    "\n",
    "for X, Y in val_dataset.take(1):  # Mostrar un batch de validación\n",
    "    print(\"Val X:\", X.shape)\n",
    "    print(\"Val Y:\", Y.shape)\n",
    "\n",
    "for X, Y in test_dataset.take(1):  # Mostrar un batch de prueba\n",
    "    print(\"Test X:\", X.shape)\n",
    "    print(\"Test Y:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definiendo Funcion Optimizacion\n",
    "Se ha intentado modularizar pero resulta en problems de pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "counter = 1\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def F_objective(learning_rate, \n",
    "     in_activation, h_activation, out_activation, \n",
    "     h_kernel_size, hidden_filters, \n",
    "     out_kernel_size, weight_kl, \n",
    "     beta_1, beta_2, epsilon, amsgrad, \n",
    "     decay_steps, decay_rate, epochs):\n",
    "    \"\"\"\n",
    "    Función objetivo para la optimización de hiperparámetros.\n",
    "    \"\"\"\n",
    "    global best_loss, counter\n",
    "    model = create_model(learning_rate, \n",
    "                        in_activation, h_activation, \n",
    "                        out_activation, h_kernel_size, \n",
    "                        hidden_filters, out_kernel_size, \n",
    "                        weight_kl, beta_1, beta_2, \n",
    "                        epsilon, amsgrad, \n",
    "                        decay_steps, decay_rate)\n",
    "\n",
    "    model.fit(train_dataset, epochs=epochs, verbose=True)\n",
    "\n",
    "    loss = model.evaluate(val_dataset, verbose=False)\n",
    "\n",
    "    print(f\"\\nLoss: {loss:.2%}\\n\")\n",
    "\n",
    "    if loss < best_loss:\n",
    "        model.save_weights(f'best_model_{counter}.weights.h5')\n",
    "        save_hyperparameters(\n",
    "            learning_rate, in_activation, \n",
    "            h_activation, out_activation, \n",
    "            h_kernel_size, hidden_filters, \n",
    "            out_kernel_size, weight_kl, \n",
    "            beta_1, beta_2, epsilon, \n",
    "            amsgrad, decay_steps, \n",
    "            decay_rate, counter\n",
    "        )\n",
    "        print(f\"Model weights and hyperparameters saved with ID: {counter}\")\n",
    "        counter += 1\n",
    "        best_loss = loss\n",
    "\n",
    "    K.clear_session()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyp_optimize(dimensions, default_parameters, n_calls=17):\n",
    "    best_loss = float('inf')\n",
    "    counter = 1\n",
    "    checkpoint_saver = CheckpointSaver(\"checkpoint.pkl\", compress=9)\n",
    "\n",
    "    start_time = time.time()\n",
    "    res = gp_minimize(\n",
    "        func=F_objective,  # Pasar la función parcial\n",
    "        dimensions=dimensions,\n",
    "        acq_func='EI', \n",
    "        n_calls=n_calls,\n",
    "        x0=default_parameters,\n",
    "        callback=[checkpoint_saver]\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    execution_time_minutes = (end_time - start_time) / 60\n",
    "    print(f\"Execution time: {execution_time_minutes:.2f} minutes\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test optimize, corre una unica vez la funcion F a optimizar\n",
    "# hyp_optimizer.run_test_optimize(train_dataset, val_dataset, verbose_train=True, verbose_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Gran Minimizacion\n",
    "La siguiente funcion correra aproximadamente `n_calls` * el tiempo que corrio el paso anterior, debes tener en cuenta si se entrenan epocas y otras que aumenten el tiempo de manera no lineal dependiendo de la accion del hiperparametro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 9s/step - loss: 0.4914\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 9s/step - loss: 0.4638\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 9s/step - loss: 0.4258\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.3820\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 9s/step - loss: 0.3397\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.3005\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.2692\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.2450\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.2269\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 9s/step - loss: 0.2149\n",
      "\n",
      "Loss: 31.28%\n",
      "\n",
      "Model weights and hyperparameters saved with ID: 1\n",
      "WARNING:tensorflow:From c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - loss: 0.3964\n",
      "Epoch 2/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0659\n",
      "Epoch 3/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0598\n",
      "Epoch 4/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0575\n",
      "Epoch 5/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0596\n",
      "Epoch 6/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0568\n",
      "Epoch 7/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0585\n",
      "Epoch 8/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0588\n",
      "Epoch 9/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.0571\n",
      "Epoch 10/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - loss: 0.0578\n",
      "Epoch 11/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0574\n",
      "Epoch 12/12\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.0594\n",
      "\n",
      "Loss: 5.99%\n",
      "\n",
      "Model weights and hyperparameters saved with ID: 2\n",
      "Epoch 1/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 8s/step - loss: 0.4967\n",
      "Epoch 2/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 8s/step - loss: 0.4906\n",
      "Epoch 3/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.4868\n",
      "Epoch 4/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7s/step - loss: 0.4809\n",
      "Epoch 5/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7s/step - loss: 0.4749\n",
      "Epoch 6/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7s/step - loss: 0.4665\n",
      "Epoch 7/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7s/step - loss: 0.4592\n",
      "Epoch 8/8\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 7s/step - loss: 0.4500\n",
      "\n",
      "Loss: 31.16%\n",
      "\n",
      "Epoch 1/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6s/step - loss: 0.4962\n",
      "Epoch 2/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - loss: 0.4924\n",
      "Epoch 3/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - loss: 0.4867\n",
      "Epoch 4/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4810\n",
      "Epoch 5/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4730\n",
      "Epoch 6/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4655\n",
      "Epoch 7/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4562\n",
      "Epoch 8/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4446\n",
      "Epoch 9/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4321\n",
      "Epoch 10/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4190\n",
      "Epoch 11/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.4063\n",
      "Epoch 12/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3930\n",
      "Epoch 13/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3821\n",
      "Epoch 14/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3705\n",
      "Epoch 15/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 6s/step - loss: 0.3563\n",
      "Epoch 16/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3476\n",
      "Epoch 17/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3385\n",
      "Epoch 18/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3270\n",
      "Epoch 19/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3149\n",
      "Epoch 20/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3094\n",
      "Epoch 21/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.3017\n",
      "Epoch 22/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.2921\n",
      "Epoch 23/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 6s/step - loss: 0.2875\n",
      "\n",
      "Loss: 8.25%\n",
      "\n",
      "Epoch 1/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7s/step - loss: 0.3783\n",
      "Epoch 2/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.2213\n",
      "Epoch 3/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.1487\n",
      "Epoch 4/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.1025\n",
      "Epoch 5/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 8s/step - loss: 0.1110\n",
      "Epoch 6/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.1259\n",
      "Epoch 7/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.1034\n",
      "Epoch 8/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.0653\n",
      "Epoch 9/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.0427\n",
      "Epoch 10/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.0382\n",
      "Epoch 11/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.0377\n",
      "Epoch 12/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.0386\n",
      "Epoch 13/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.1027\n",
      "Epoch 14/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.1089\n",
      "Epoch 15/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.0384\n",
      "Epoch 16/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 8s/step - loss: 0.0377\n",
      "Epoch 17/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - loss: 0.0386\n",
      "Epoch 18/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.0375\n",
      "Epoch 19/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - loss: 0.0372\n",
      "Epoch 20/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7s/step - loss: 0.0380\n",
      "Epoch 21/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7s/step - loss: 0.0374\n",
      "\n",
      "Loss: 3.81%\n",
      "\n",
      "Model weights and hyperparameters saved with ID: 3\n",
      "Epoch 1/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5934\n",
      "Epoch 2/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5883\n",
      "Epoch 3/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5834\n",
      "Epoch 4/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5796\n",
      "Epoch 5/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5755\n",
      "Epoch 6/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5720\n",
      "Epoch 7/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5677\n",
      "Epoch 8/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5646\n",
      "Epoch 9/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5614\n",
      "Epoch 10/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5571\n",
      "Epoch 11/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5546\n",
      "Epoch 12/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5518\n",
      "Epoch 13/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5483\n",
      "Epoch 14/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7s/step - loss: 0.5462\n",
      "Epoch 15/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5435\n",
      "Epoch 16/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5418\n",
      "Epoch 17/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5400\n",
      "Epoch 18/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5387\n",
      "Epoch 19/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5373\n",
      "Epoch 20/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5352\n",
      "Epoch 21/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7s/step - loss: 0.5340\n",
      "Epoch 22/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5326\n",
      "Epoch 23/23\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7s/step - loss: 0.5306\n",
      "\n",
      "Loss: 8.57%\n",
      "\n",
      "Epoch 1/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7s/step - loss: 0.6004\n",
      "Epoch 2/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5722\n",
      "Epoch 3/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5474\n",
      "Epoch 4/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5303\n",
      "Epoch 5/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5145\n",
      "Epoch 6/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.5031\n",
      "Epoch 7/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4938\n",
      "Epoch 8/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7s/step - loss: 0.4837\n",
      "Epoch 9/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4758\n",
      "Epoch 10/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4683\n",
      "Epoch 11/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4612\n",
      "Epoch 12/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4553\n",
      "Epoch 13/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4486\n",
      "Epoch 14/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4428\n",
      "Epoch 15/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4385\n",
      "Epoch 16/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4333\n",
      "Epoch 17/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7s/step - loss: 0.4273\n",
      "\n",
      "Loss: 13.00%\n",
      "\n",
      "Epoch 1/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 17s/step - loss: 0.4150\n",
      "Epoch 2/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 16s/step - loss: 0.1751\n",
      "Epoch 3/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 16s/step - loss: 0.0640\n",
      "Epoch 4/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 16s/step - loss: 0.0588\n",
      "Epoch 5/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 16s/step - loss: 0.0762\n",
      "Epoch 6/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 16s/step - loss: 0.0796\n",
      "Epoch 7/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 16s/step - loss: 0.1455\n",
      "Epoch 8/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 16s/step - loss: 0.0459\n",
      "Epoch 9/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 16s/step - loss: 0.0428\n",
      "Epoch 10/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 16s/step - loss: 0.0440\n",
      "Epoch 11/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 16s/step - loss: 0.0438\n",
      "Epoch 12/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 16s/step - loss: 0.0437\n",
      "Epoch 13/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 16s/step - loss: 0.0433\n",
      "Epoch 14/14\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 16s/step - loss: 0.0437\n",
      "\n",
      "Loss: 4.40%\n",
      "\n",
      "Epoch 1/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 23s/step - loss: 0.4202\n",
      "Epoch 2/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 23s/step - loss: 0.2697\n",
      "Epoch 3/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 23s/step - loss: 0.0564\n",
      "Epoch 4/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 23s/step - loss: 0.0458\n",
      "Epoch 5/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 24s/step - loss: 0.0463\n",
      "Epoch 6/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0469\n",
      "Epoch 7/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 23s/step - loss: 0.0461\n",
      "Epoch 8/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 23s/step - loss: 0.0453\n",
      "Epoch 9/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0440\n",
      "Epoch 10/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 23s/step - loss: 0.0422\n",
      "Epoch 11/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0414\n",
      "Epoch 12/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 23s/step - loss: 0.0405\n",
      "Epoch 13/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 23s/step - loss: 0.0402\n",
      "Epoch 14/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0397\n",
      "Epoch 15/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 23s/step - loss: 0.0391\n",
      "Epoch 16/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 23s/step - loss: 0.0380\n",
      "Epoch 17/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 23s/step - loss: 0.0372\n",
      "Epoch 18/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0361\n",
      "Epoch 19/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0344\n",
      "Epoch 20/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 23s/step - loss: 0.0336\n",
      "Epoch 21/21\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 23s/step - loss: 0.0334\n",
      "\n",
      "Loss: 19.89%\n",
      "\n",
      "Epoch 1/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 25s/step - loss: 0.6805\n",
      "Epoch 2/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 25s/step - loss: 0.6714\n",
      "Epoch 3/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 25s/step - loss: 0.6649\n",
      "Epoch 4/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 25s/step - loss: 0.6607\n",
      "Epoch 5/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 25s/step - loss: 0.6576\n",
      "Epoch 6/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 25s/step - loss: 0.6562\n",
      "Epoch 7/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6539\n",
      "Epoch 8/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 25s/step - loss: 0.6523\n",
      "Epoch 9/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 25s/step - loss: 0.6508\n",
      "Epoch 10/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 25s/step - loss: 0.6490\n",
      "Epoch 11/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6466\n",
      "Epoch 12/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 25s/step - loss: 0.6454\n",
      "Epoch 13/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 25s/step - loss: 0.6449\n",
      "Epoch 14/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6420\n",
      "Epoch 15/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 25s/step - loss: 0.6412\n",
      "Epoch 16/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6382\n",
      "Epoch 17/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6370\n",
      "Epoch 18/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 25s/step - loss: 0.6359\n",
      "Epoch 19/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 25s/step - loss: 0.6353\n",
      "\n",
      "Loss: 31.14%\n",
      "\n",
      "Epoch 1/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 34s/step - loss: 0.4971\n",
      "Epoch 2/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 34s/step - loss: 0.4897\n",
      "Epoch 3/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 34s/step - loss: 0.4837\n",
      "Epoch 4/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 34s/step - loss: 0.4765\n",
      "Epoch 5/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 34s/step - loss: 0.4673\n",
      "Epoch 6/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 34s/step - loss: 0.4560\n",
      "Epoch 7/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 34s/step - loss: 0.4402\n",
      "Epoch 8/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 34s/step - loss: 0.4192\n",
      "Epoch 9/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 34s/step - loss: 0.3979\n",
      "Epoch 10/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 34s/step - loss: 0.3769\n",
      "Epoch 11/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 34s/step - loss: 0.3543\n",
      "Epoch 12/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 34s/step - loss: 0.3295\n",
      "Epoch 13/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 34s/step - loss: 0.3141\n",
      "Epoch 14/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 34s/step - loss: 0.2958\n",
      "Epoch 15/15\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 38s/step - loss: 0.2861\n",
      "\n",
      "Loss: 99.25%\n",
      "\n",
      "Epoch 1/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - loss: 0.4910\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.4885\n",
      "Epoch 3/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.4883\n",
      "Epoch 4/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4874\n",
      "Epoch 5/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4872\n",
      "Epoch 6/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4839\n",
      "Epoch 7/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4833\n",
      "Epoch 8/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4807\n",
      "Epoch 9/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4788\n",
      "Epoch 10/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4758\n",
      "Epoch 11/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4732\n",
      "Epoch 12/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4669\n",
      "Epoch 13/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4638\n",
      "Epoch 14/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4591\n",
      "Epoch 15/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4538\n",
      "Epoch 16/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4487\n",
      "Epoch 17/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4419\n",
      "Epoch 18/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4376\n",
      "Epoch 19/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4295\n",
      "Epoch 20/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.4227\n",
      "Epoch 21/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.4162\n",
      "Epoch 22/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4069\n",
      "Epoch 23/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4000\n",
      "Epoch 24/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3923\n",
      "Epoch 25/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3849\n",
      "\n",
      "Loss: 9.61%\n",
      "\n",
      "Epoch 1/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5s/step - loss: 0.4446\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.3046\n",
      "Epoch 3/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.2739\n",
      "Epoch 4/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.2411\n",
      "Epoch 5/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.2344\n",
      "Epoch 6/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.2250\n",
      "Epoch 7/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1999\n",
      "Epoch 8/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1766\n",
      "Epoch 9/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1646\n",
      "Epoch 10/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1458\n",
      "Epoch 11/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1410\n",
      "Epoch 12/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1360\n",
      "Epoch 13/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1250\n",
      "Epoch 14/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.1128\n",
      "Epoch 15/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 5s/step - loss: 0.1021\n",
      "Epoch 16/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0911\n",
      "Epoch 17/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0845\n",
      "Epoch 18/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0776\n",
      "Epoch 19/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0734\n",
      "Epoch 20/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0692\n",
      "Epoch 21/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0692\n",
      "Epoch 22/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0690\n",
      "Epoch 23/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0681\n",
      "Epoch 24/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0680\n",
      "Epoch 25/25\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - loss: 0.0683\n",
      "\n",
      "Loss: 98.71%\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - loss: 0.4994\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4926\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - loss: 0.4873\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4810\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4754\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4676\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4578\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4464\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - loss: 0.4354\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 0.4240\n",
      "\n",
      "Loss: 24.85%\n",
      "\n",
      "Epoch 1/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.4651\n",
      "Epoch 2/19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.1179\n",
      "Epoch 3/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0435\n",
      "Epoch 4/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0421\n",
      "Epoch 5/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0419\n",
      "Epoch 6/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0411\n",
      "Epoch 7/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0418\n",
      "Epoch 8/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0423\n",
      "Epoch 9/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0422\n",
      "Epoch 10/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0422\n",
      "Epoch 11/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0422\n",
      "Epoch 12/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0420\n",
      "Epoch 13/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0422\n",
      "Epoch 14/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0426\n",
      "Epoch 15/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0420\n",
      "Epoch 16/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0419\n",
      "Epoch 17/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.0424\n",
      "Epoch 18/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.0421\n",
      "Epoch 19/19\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.0425\n",
      "\n",
      "Loss: 4.29%\n",
      "\n",
      "Epoch 1/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 6s/step - loss: 0.4985\n",
      "Epoch 2/17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.3963\n",
      "Epoch 3/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.3614\n",
      "Epoch 4/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.3394\n",
      "Epoch 5/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7s/step - loss: 0.3257\n",
      "Epoch 6/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.3145\n",
      "Epoch 7/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.3047\n",
      "Epoch 8/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.2956\n",
      "Epoch 9/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2875\n",
      "Epoch 10/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2813\n",
      "Epoch 11/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2752\n",
      "Epoch 12/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2692\n",
      "Epoch 13/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.2637\n",
      "Epoch 14/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.2583\n",
      "Epoch 15/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 6s/step - loss: 0.2528\n",
      "Epoch 16/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2477\n",
      "Epoch 17/17\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 6s/step - loss: 0.2429\n",
      "\n",
      "Loss: 27.84%\n",
      "\n",
      "Epoch 1/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 72s/step - loss: 0.6045\n",
      "Epoch 2/22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\contextlib.py:137: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 73s/step - loss: 0.5194\n",
      "Epoch 3/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 73s/step - loss: 0.4589\n",
      "Epoch 4/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 74s/step - loss: 0.4131\n",
      "Epoch 5/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 69s/step - loss: 0.3711\n",
      "Epoch 6/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m856s\u001b[0m 76s/step - loss: 0.3405\n",
      "Epoch 7/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 77s/step - loss: 0.3147\n",
      "Epoch 8/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 77s/step - loss: 0.2907\n",
      "Epoch 9/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m801s\u001b[0m 73s/step - loss: 0.2688\n",
      "Epoch 10/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m776s\u001b[0m 69s/step - loss: 0.2508\n",
      "Epoch 11/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m756s\u001b[0m 68s/step - loss: 0.2322\n",
      "Epoch 12/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 76s/step - loss: 0.2163\n",
      "Epoch 13/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 65s/step - loss: 0.2047\n",
      "Epoch 14/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 66s/step - loss: 0.1893\n",
      "Epoch 15/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 68s/step - loss: 0.1791\n",
      "Epoch 16/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 63s/step - loss: 0.1676\n",
      "Epoch 17/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m907s\u001b[0m 83s/step - loss: 0.1594\n",
      "Epoch 18/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 66s/step - loss: 0.1491\n",
      "Epoch 19/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m833s\u001b[0m 76s/step - loss: 0.1404\n",
      "Epoch 20/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 74s/step - loss: 0.1354\n",
      "Epoch 21/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 58s/step - loss: 0.1284\n",
      "Epoch 22/22\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m748s\u001b[0m 68s/step - loss: 0.1201\n",
      "\n",
      "Loss: 4.84%\n",
      "\n",
      "Execution time: 806.92 minutes\n"
     ]
    }
   ],
   "source": [
    "res = run_hyp_optimize(dimensions, default_parameters, n_calls=17)\n",
    "\n",
    "# Guardar el objeto res, para hacer estadistica despues\n",
    "with open('optimization_results.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.plots import plot_histogram, plot_objective_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space([Real(low=1e-06, high=0.01, prior='log-uniform', transform='normalize'),\n",
      "       Categorical(categories=('relu', 'sigmoid', 'tanh'), prior=None),\n",
      "       Categorical(categories=('relu', 'sigmoid', 'tanh'), prior=None),\n",
      "       Categorical(categories=('relu', 'sigmoid', 'tanh'), prior=None),\n",
      "       Integer(low=2, high=7, prior='uniform', transform='normalize'),\n",
      "       Integer(low=16, high=128, prior='uniform', transform='normalize'),\n",
      "       Integer(low=2, high=7, prior='uniform', transform='normalize'),\n",
      "       Real(low=0.01, high=2.0, prior='log-uniform', transform='normalize'),\n",
      "       Real(low=0.0, high=0.99, prior='uniform', transform='normalize'),\n",
      "       Real(low=0.0, high=0.999, prior='uniform', transform='normalize'),\n",
      "       Real(low=1e-08, high=0.0001, prior='log-uniform', transform='normalize'),\n",
      "       Categorical(categories=(True, False), prior=None),\n",
      "       Integer(low=1000, high=50000, prior='uniform', transform='normalize'),\n",
      "       Real(low=0.8, high=0.99, prior='uniform', transform='normalize'),\n",
      "       Integer(low=5, high=25, prior='uniform', transform='normalize')])\n",
      "[0.0006287608261952666, 'sigmoid', 'sigmoid', 'relu', 5, 46, 7, 0.06520235535315982, 0.8203556168159303, 0.15558005063355992, 2.7742815780300855e-05, False, 8410, 0.9232016808113246, 21]\n",
      "Accuracy:  0.03812620788812637\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(res)\n",
    "print(res.space)\n",
    "print(res.x)\n",
    "print(\"Accuracy: \", res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_histogram, plot_objective_2D\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdimension_identifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\site-packages\\skopt\\plots.py:1363\u001b[0m, in \u001b[0;36mplot_histogram\u001b[1;34m(result, dimension_identifier, bins, rotate_labels, ax)\u001b[0m\n\u001b[0;32m   1360\u001b[0m index, dimension \u001b[38;5;241m=\u001b[39m space[dimension_identifier]\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;66;03m# Get the samples from the optimization-log for that particular dimension.\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m samples \u001b[38;5;241m=\u001b[39m [x[index] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mx_iters]\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1366\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\danij\\anaconda3\\envs\\tf\\lib\\site-packages\\skopt\\plots.py:1363\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1360\u001b[0m index, dimension \u001b[38;5;241m=\u001b[39m space[dimension_identifier]\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;66;03m# Get the samples from the optimization-log for that particular dimension.\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m samples \u001b[38;5;241m=\u001b[39m [\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mx_iters]\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1366\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "source": [
    "from skopt.plots import plot_histogram, plot_objective_2D\n",
    "\n",
    "plot_histogram(result=res,  dimension_identifier='activation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_objective(result=res, dimensions=dimension_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_evaluations(result=res, dimensions=dimension_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
